import 'dotenv/config'
import { createClient } from '@supabase/supabase-js'
import fs from 'fs'
import { parse } from 'csv-parse/sync'
import iconv from 'iconv-lite'

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_KEY
)

async function uploadProductsFromCSV(csvPath) {
  console.log(`ğŸ“‚ CSV íŒŒì¼ ì½ëŠ” ì¤‘: ${csvPath}`)

  // EUC-KR/CP949 ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
  const buffer = fs.readFileSync(csvPath)
  const fileContent = iconv.decode(buffer, 'euc-kr')
  const records = parse(fileContent, {
    columns: true,
    skip_empty_lines: true,
  })

  console.log(`ğŸ“¦ ${records.length}ê°œì˜ ì œí’ˆ ë°œê²¬`)

  if (records.length === 0) {
    console.log('âš ï¸ ì—…ë¡œë“œí•  ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤')
    return
  }

  const products = records.map((row) => ({
    source: row.source || null,
    source_product_id: row.source_product_id || null,
    url: row.url || null,
    title: row.title || null,
    brand: row.brand || null,
    category: row.category || null,
    price: row.price && row.price.trim() ? parseInt(row.price) : null,
    currency: row.currency || null,
    rating_avg: row.rating_avg && row.rating_avg.trim() ? parseFloat(row.rating_avg) : null,
    rating_count: row.rating_count && row.rating_count.trim() ? parseInt(row.rating_count) : null,
  }))

  console.log('â¬†ï¸ Supabaseì— ì—…ë¡œë“œ ì¤‘...')

  const { data, error } = await supabase
    .from('products')
    .upsert(products, { onConflict: 'source,source_product_id' })

  if (error) {
    console.error('âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error)
    throw error
  }

  console.log(`âœ… ${products.length}ê°œì˜ ì œí’ˆì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!`)
  console.log('ğŸ“Š ì—…ë¡œë“œëœ ì œí’ˆ:')
  products.forEach((p) => {
    console.log(`  - ${p.brand}: ${p.title?.substring(0, 50)}...`)
  })
}

async function uploadReviewsFromCSV(csvPath) {
  console.log(`ğŸ“‚ CSV íŒŒì¼ ì½ëŠ” ì¤‘: ${csvPath}`)

  // EUC-KR/CP949 ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
  const buffer = fs.readFileSync(csvPath)
  const fileContent = iconv.decode(buffer, 'euc-kr')
  const records = parse(fileContent, {
    columns: true,
    skip_empty_lines: true,
  })

  console.log(`ğŸ“ ${records.length}ê°œì˜ ë¦¬ë·° ë°œê²¬`)

  if (records.length === 0) {
    console.log('âš ï¸ ì—…ë¡œë“œí•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤')
    return
  }

  // 1. products í…Œì´ë¸”ì—ì„œ source_product_id -> id ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
  console.log('ğŸ” ì œí’ˆ ID ë§¤í•‘ ì¡°íšŒ ì¤‘...')
  const { data: products, error: productsError } = await supabase
    .from('products')
    .select('id, source, source_product_id')

  if (productsError) {
    console.error('âŒ ì œí’ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:', productsError)
    throw productsError
  }

  // source_product_id -> id ë§¤í•‘ ìƒì„±
  const productIdMap = new Map()
  products.forEach((p) => {
    const key = `${p.source}:${p.source_product_id}`
    productIdMap.set(key, p.id)
  })

  console.log(`âœ… ${productIdMap.size}ê°œì˜ ì œí’ˆ ë§¤í•‘ ì™„ë£Œ`)

  // 2. CSVì˜ product_id(source_product_id)ë¥¼ ì‹¤ì œ idë¡œ ë³€í™˜
  const reviews = []
  const skipped = []

  for (const row of records) {
    const sourceProductId = row.product_id?.trim()
    const source = row.source?.trim() || 'iHerb'
    const key = `${source}:${sourceProductId}`
    const actualProductId = productIdMap.get(key)

    if (!actualProductId) {
      skipped.push({ source, sourceProductId })
      continue
    }

    // source_review_idë¥¼ ê³ ìœ í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ source_product_id í¬í•¨
    const originalReviewId = row.source_review_id?.trim() || '0'
    const uniqueReviewId = `${sourceProductId}-${originalReviewId}`

    reviews.push({
      product_id: actualProductId,
      source: source,
      source_review_id: uniqueReviewId,
      author: row.author || null,
      rating: row.rating && row.rating.trim() ? parseInt(row.rating) : null,
      title: row.title || null,
      body: row.body || null,
      language: row.language || null,
      helpful_count: row.helpful_count && row.helpful_count.trim() ? parseInt(row.helpful_count) : null,
      review_date: row.review_date || null,
    })
  }

  if (skipped.length > 0) {
    console.log(`âš ï¸ ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ${skipped.length}ê°œ ë¦¬ë·°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤:`)
    skipped.forEach((s) => console.log(`  - ${s.source}:${s.sourceProductId}`))
  }

  if (reviews.length === 0) {
    console.log('âš ï¸ ì—…ë¡œë“œí•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤')
    return
  }

  // ì¤‘ë³µ ì œê±°: source + source_review_id ê¸°ì¤€ìœ¼ë¡œ ë§ˆì§€ë§‰ í•­ëª©ë§Œ ìœ ì§€
  const uniqueReviews = []
  const seen = new Set()

  for (const review of reviews) {
    const key = `${review.source}:${review.source_review_id}`
    if (!seen.has(key)) {
      seen.add(key)
      uniqueReviews.push(review)
    }
  }

  if (reviews.length !== uniqueReviews.length) {
    console.log(`âš ï¸ ${reviews.length - uniqueReviews.length}ê°œì˜ ì¤‘ë³µëœ ë¦¬ë·°ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤`)
  }

  console.log(`â¬†ï¸ ${uniqueReviews.length}ê°œ ë¦¬ë·°ë¥¼ Supabaseì— ì—…ë¡œë“œ ì¤‘...`)

  const { data, error } = await supabase
    .from('reviews')
    .upsert(uniqueReviews, { onConflict: 'source,source_review_id' })

  if (error) {
    console.error('âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error)
    throw error
  }

  console.log(`âœ… ${uniqueReviews.length}ê°œì˜ ë¦¬ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!`)
}

const mode = process.argv[2] || 'products'

try {
  if (mode === 'products' || mode === 'all') {
    await uploadProductsFromCSV('products_rows.csv')
  }

  if (mode === 'reviews' || mode === 'all') {
    await uploadReviewsFromCSV('reviews_rows.csv')
  }

  console.log('âœ… ëª¨ë“  ì—…ë¡œë“œ ì™„ë£Œ!')
} catch (e) {
  console.error('âŒ Error:', e?.message || e)
  process.exit(1)
}
