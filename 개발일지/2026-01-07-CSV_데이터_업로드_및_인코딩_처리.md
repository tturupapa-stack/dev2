# 2026-01-07 개발일지: CSV 데이터 업로드 및 한글 인코딩 처리

## 작업 개요
iHerb 제품 및 리뷰 데이터를 CSV 파일에서 Supabase DB로 업로드하는 기능 구현

## 주요 작업 내용

### 1. CSV 데이터 업로드 스크립트 작성
- **목적**: products_rows.csv와 reviews_rows.csv 파일을 Supabase에 업로드
- **구현 파일**: `upload-products-csv.mjs`
- **기능**:
  - CSV 파일 파싱 및 Supabase 테이블에 upsert
  - Product ID 매핑: CSV의 source_product_id를 실제 DB id로 자동 변환
  - 중복 리뷰 자동 제거
  - 고유 ID 생성: `{source_product_id}-{review_id}` 형식

### 2. 한글 인코딩 문제 해결
#### 문제
- CSV 파일을 UTF-8로 읽어서 Supabase에 업로드했더니 한글이 깨짐
- 예: "루테인" → "������"

#### 원인 분석
```bash
file -bi products_rows.csv
# 결과: text/csv; charset=iso-8859-1
```
- CSV 파일이 **EUC-KR/CP949** 인코딩으로 저장되어 있었음
- Node.js의 기본 파일 읽기는 UTF-8 가정

#### 해결 방법
1. **인코딩 테스트 스크립트 작성** (`test-encoding.mjs`)
   - 여러 인코딩(utf-8, euc-kr, cp949, utf-16le, utf-16be)으로 파일 읽기 테스트
   - EUC-KR/CP949가 올바른 인코딩임을 확인

2. **iconv-lite 패키지 추가**
   ```bash
   npm install iconv-lite
   ```

3. **업로드 스크립트 수정**
   ```javascript
   // 변경 전
   const fileContent = fs.readFileSync(csvPath, 'utf-8')

   // 변경 후
   const buffer = fs.readFileSync(csvPath)
   const fileContent = iconv.decode(buffer, 'euc-kr')
   ```

### 3. Python 백업 업로더 작성
- **파일**: `data_manager/db_uploader.py`
- **목적**: Python 환경에서도 CSV 업로드 가능하도록 백업 스크립트 제공
- **상태**: 작성 완료 (향후 사용 가능)

## 업로드 결과

### Products 테이블
- **총 5개 제품 업로드 완료**
  1. California Gold Nutrition - 루테인 (iHerb)
  2. Doctor's Best - Lutemax 2020
  3. Solaray - L-라이신모노라우린
  4. Natural Factors - 제아잔틴 함유 루테인
  5. Sports Research - 루테인 + 제아잔틴

### Reviews 테이블
- **총 50개 리뷰 업로드 완료**
- 10개 중복 리뷰 자동 제거됨

## 기술 스택 & 의존성 추가

### 새로 추가된 패키지
```json
{
  "csv-parse": "^6.1.0",     // CSV 파싱
  "iconv-lite": "^0.7.1"      // 인코딩 변환
}
```

### 사용 기술
- **JavaScript/Node.js**: 메인 업로드 스크립트
- **Supabase JavaScript Client**: DB 연동
- **iconv-lite**: EUC-KR → UTF-8 변환
- **csv-parse**: CSV 파일 파싱

## 파일 구조

```
data_manager/
  └── db_uploader.py           # Python 기반 업로더 (백업)

upload-products-csv.mjs        # 메인 CSV 업로드 스크립트
test-encoding.mjs              # 인코딩 테스트 유틸리티
products_rows.csv              # 제품 데이터 (5개)
reviews_rows.csv               # 리뷰 데이터 (60개)
```

## Git 커밋 내역

```
commit dc13561
feat: CSV 데이터 업로드 도구 추가 - EUC-KR 인코딩 지원으로 한글 처리

- products_rows.csv, reviews_rows.csv 추가
- upload-products-csv.mjs: Supabase 업로드 스크립트
- data_manager/db_uploader.py: Python 업로더
- test-encoding.mjs: 인코딩 테스트 유틸리티
- iconv-lite, csv-parse 의존성 추가
```

## 트러블슈팅

### Issue 1: product_id null 오류
**문제**: reviews 테이블 업로드 시 `product_id` null 제약 조건 위반
```
null value in column "product_id" violates not-null constraint
```

**원인**: CSV의 `product_id` 컬럼에 source_product_id(문자열)가 들어있었음

**해결**:
1. products 테이블에서 source_product_id → id 매핑 조회
2. 매핑 테이블 생성하여 자동 변환

### Issue 2: 중복 리뷰 오류
**문제**: `ON CONFLICT DO UPDATE command cannot affect row a second time`

**원인**: CSV에 동일한 source_review_id가 여러 제품에서 중복 (1, 2, 3...)

**해결**:
1. 고유 ID 생성: `{source_product_id}-{review_id}`
2. 중복 자동 제거 로직 추가

### Issue 3: 한글 깨짐
**문제**: Supabase에 저장된 한글이 모두 깨짐

**원인**: CSV 파일이 EUC-KR 인코딩인데 UTF-8로 읽음

**해결**: iconv-lite로 EUC-KR → UTF-8 변환 후 업로드

## 다음 단계

1. Streamlit 앱에서 업로드된 데이터 조회 및 표시
2. 팩트체크 로직을 실제 DB 데이터에 적용
3. AI 분석 결과를 reviews 테이블에 저장하는 기능 추가

## 배운 점

1. **인코딩의 중요성**:
   - 한글 데이터 처리 시 인코딩 확인 필수
   - `file -bi` 명령으로 파일 인코딩 확인 가능
   - Windows 환경에서는 EUC-KR/CP949가 기본일 수 있음

2. **CSV 데이터 전처리**:
   - 중복 데이터 자동 제거 로직 필요
   - 외래키 관계 있는 데이터는 매핑 테이블 활용

3. **Supabase upsert**:
   - `onConflict` 옵션으로 중복 처리
   - 제약 조건 확인 필수 (NOT NULL, UNIQUE 등)

## 참고 자료
- [iconv-lite Documentation](https://www.npmjs.com/package/iconv-lite)
- [csv-parse Documentation](https://www.npmjs.com/package/csv-parse)
- [Supabase JavaScript Client](https://supabase.com/docs/reference/javascript)
