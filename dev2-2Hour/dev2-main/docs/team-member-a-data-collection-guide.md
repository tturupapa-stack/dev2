# íŒ€ì› A: ë°ì´í„° ìˆ˜ì§‘ ë° DB êµ¬ì¶• ë‹´ë‹¹ ê°€ì´ë“œ

## ğŸ“‹ ì—­í•  ê°œìš”

**ëª©í‘œ:** "ë£¨í…Œì¸ ì œí’ˆ 5ì¢…ì˜ ë¦¬ë·° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Supabaseì— ì €ì¥í•œë‹¤."

iHerbì—ì„œ ë£¨í…Œì¸ ì œí’ˆ 5ì¢…ì„ ì„ ì •í•˜ê³ , ê° ì œí’ˆë‹¹ 20ê°œì˜ ë¦¬ë·°(ì´ 100ê°œ)ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” **1íšŒì„± ì‘ì—…**ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

---

## ğŸ¯ ìƒì„¸ ë¯¸ì…˜

### 1. ì œí’ˆ ì„ ì • ë° ë°ì´í„° ìˆ˜ì§‘
- iHerbì—ì„œ ë£¨í…Œì¸ ì œí’ˆ 5ì¢… ì„ ì •
- ê° ì œí’ˆë‹¹ ë¦¬ë·° 20ê°œ ìˆ˜ì§‘ (í¬ë¡¤ë§ ë˜ëŠ” ìˆ˜ë™)
- ì œí’ˆ ì •ë³´ ë° ë¦¬ë·° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

### 2. ë°ì´í„° ì •ì œ
- ì¤‘ë³µ ë¦¬ë·° ì œê±°
- íŠ¹ìˆ˜ë¬¸ì ë° ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
- íƒœê·¸ ì •ê·œí™” (ì¬êµ¬ë§¤, í•œë‹¬ì‚¬ìš© ë“±)

### 3. Supabase DB êµ¬ì¶•
- í…Œì´ë¸” ì„¤ê³„ (products, reviews)
- ë°ì´í„° ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
flowchart TD
    Start[ë£¨í…Œì¸ ì œí’ˆ 5ì¢… ì„ ì •] --> Collect{ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•}

    Collect -->|í¬ë¡¤ë§| Scraper[iHerb ìŠ¤í¬ë˜í¼]
    Collect -->|ìˆ˜ë™ ìˆ˜ì§‘| Manual[ìˆ˜ë™ ì…ë ¥]

    Scraper --> ParseHTML[HTML íŒŒì‹±]
    Manual --> ParseHTML

    ParseHTML --> Extract[ë°ì´í„° ì¶”ì¶œ]
    Extract --> ExtractProduct[ì œí’ˆ ì •ë³´]
    Extract --> ExtractReviews[ë¦¬ë·° ë°ì´í„°]

    ExtractProduct --> Clean[ë°ì´í„° ì •ì œ]
    ExtractReviews --> Clean

    Clean --> RemoveDup[ì¤‘ë³µ ì œê±°]
    RemoveDup --> Normalize[íƒœê·¸ ì •ê·œí™”]
    Normalize --> Validate[ë°ì´í„° ê²€ì¦]

    Validate --> Upload[Supabase ì—…ë¡œë“œ]
    Upload --> Products[(products í…Œì´ë¸”)]
    Upload --> Reviews[(reviews í…Œì´ë¸”)]

    Products --> Verify[ë°ì´í„° ê²€ì¦]
    Reviews --> Verify
    Verify --> End[ì™„ë£Œ: 5ì œí’ˆ, 100ë¦¬ë·°]
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
data_manager/
â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ scraper.py               # iHerb ìŠ¤í¬ë˜í¼ (ì„ íƒì  ì‚¬ìš©)
â”‚   â””â”€â”€ IHerbScraper         # iHerb ë¦¬ë·° í¬ë¡¤ëŸ¬
â”œâ”€â”€ data_cleaner.py          # ë°ì´í„° ì •ì œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ ReviewCleaner        # ë¦¬ë·° ì •ì œ í´ë˜ìŠ¤
â”‚   â””â”€â”€ TagNormalizer        # íƒœê·¸ ì •ê·œí™” í´ë˜ìŠ¤
â”œâ”€â”€ supabase_client.py       # Supabase í´ë¼ì´ì–¸íŠ¸
â”‚   â””â”€â”€ SupabaseClient       # DB ì—°ê²° ë° CRUD
â”œâ”€â”€ db_uploader.py           # DB ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ upload_all_data()    # ë©”ì¸ ì—…ë¡œë“œ í•¨ìˆ˜
â””â”€â”€ config.py                # ì„¤ì • íŒŒì¼
    â”œâ”€â”€ SUPABASE_CONFIG      # Supabase ì„¤ì •
    â””â”€â”€ PRODUCTS_LIST        # ìˆ˜ì§‘ ëŒ€ìƒ ì œí’ˆ ëª©ë¡
```

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì›¹ ìŠ¤í¬ë˜í•‘ (ì„ íƒì ):**
  - `selenium` (4.15.0+): ë™ì  í˜ì´ì§€ ì²˜ë¦¬
  - `beautifulsoup4` (4.12.0+): HTML íŒŒì‹±
  - `requests` (2.31.0+): HTTP ìš”ì²­

- **ë°ì´í„°ë² ì´ìŠ¤:**
  - `supabase` (2.0.0+): Supabase Python í´ë¼ì´ì–¸íŠ¸

- **ë°ì´í„° ì²˜ë¦¬:**
  - `pandas` (2.0.0+): ë°ì´í„° ì¡°ì‘
  - `python-dotenv` (1.0.0+): í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬

---

## ğŸ“Š Supabase í…Œì´ë¸” ì„¤ê³„

### products í…Œì´ë¸”
```sql
CREATE TABLE products (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    brand VARCHAR(255),
    price DECIMAL(10, 2),
    serving_size VARCHAR(100),
    servings_per_container INTEGER,
    ingredients JSONB,           -- [{name, amount, daily_value}]
    other_ingredients TEXT[],
    warnings TEXT[],
    product_url TEXT,
    image_url TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### reviews í…Œì´ë¸”
```sql
CREATE TABLE reviews (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    product_id UUID REFERENCES products(id) ON DELETE CASCADE,
    text TEXT NOT NULL,
    rating INTEGER CHECK (rating >= 1 AND rating <= 5),
    date DATE,
    reorder BOOLEAN DEFAULT FALSE,
    one_month_use BOOLEAN DEFAULT FALSE,
    reviewer VARCHAR(255),
    verified BOOLEAN DEFAULT FALSE,
    helpful_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ì¶”ê°€
CREATE INDEX idx_reviews_product_id ON reviews(product_id);
CREATE INDEX idx_reviews_rating ON reviews(rating);
```

---

## ğŸ“ ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜ ì„¤ê³„

### 1. `supabase_client.py`

```python
# data_manager/supabase_client.py
import os
from supabase import create_client, Client
from dotenv import load_dotenv
from typing import List, Dict, Optional

load_dotenv()

class SupabaseClient:
    """Supabase ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")
        self.client: Client = create_client(url, key)

    def insert_product(self, product: Dict) -> Dict:
        """
        ì œí’ˆ ì •ë³´ ì €ì¥

        Args:
            product: {
                'name': str,
                'brand': str,
                'price': float,
                'serving_size': str,
                'servings_per_container': int,
                'ingredients': List[Dict],
                'other_ingredients': List[str],
                'warnings': List[str],
                'product_url': str,
                'image_url': str
            }

        Returns:
            Dict: ì €ì¥ëœ ì œí’ˆ ë°ì´í„° (id í¬í•¨)
        """
        response = self.client.table('products').insert(product).execute()
        return response.data[0]

    def insert_reviews(self, reviews: List[Dict]) -> List[Dict]:
        """
        ë¦¬ë·° ì¼ê´„ ì €ì¥

        Args:
            reviews: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ (product_id í¬í•¨)

        Returns:
            List[Dict]: ì €ì¥ëœ ë¦¬ë·° ë°ì´í„°
        """
        response = self.client.table('reviews').insert(reviews).execute()
        return response.data

    def get_all_products(self) -> List[Dict]:
        """ì „ì²´ ì œí’ˆ ëª©ë¡ ì¡°íšŒ"""
        response = self.client.table('products').select('*').execute()
        return response.data

    def get_reviews_by_product(self, product_id: str) -> List[Dict]:
        """ì œí’ˆë³„ ë¦¬ë·° ì¡°íšŒ"""
        response = self.client.table('reviews')\
            .select('*')\
            .eq('product_id', product_id)\
            .execute()
        return response.data

    def search_products(self, keyword: str) -> List[Dict]:
        """ì œí’ˆ ê²€ìƒ‰ (ì´ë¦„ ê¸°ì¤€)"""
        response = self.client.table('products')\
            .select('*')\
            .ilike('name', f'%{keyword}%')\
            .execute()
        return response.data
```

### 2. `scraper.py` (ì„ íƒì  ì‚¬ìš©)

```python
# data_manager/scraper.py
from abc import ABC, abstractmethod
from typing import List, Dict
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time

class IHerbScraper:
    """iHerb ë¦¬ë·° ìŠ¤í¬ë˜í¼"""

    def __init__(self, url: str, max_reviews: int = 20):
        self.url = url
        self.max_reviews = max_reviews
        self.driver = None

    def scrape(self) -> Dict:
        """
        iHerb ì œí’ˆ ì •ë³´ ë° ë¦¬ë·° ìˆ˜ì§‘

        Returns:
            Dict: {
                'product': {...},
                'reviews': [...]
            }
        """
        try:
            self._setup_driver()
            self.driver.get(self.url)
            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

            product = self._parse_product()
            reviews = self._parse_reviews()

            return {
                'product': product,
                'reviews': reviews[:self.max_reviews]
            }
        finally:
            self._close_driver()

    def _setup_driver(self):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        self.driver = webdriver.Chrome(options=options)

    def _close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()

    def _parse_product(self) -> Dict:
        """ì œí’ˆ ì •ë³´ íŒŒì‹±"""
        soup = BeautifulSoup(self.driver.page_source, 'html.parser')

        # iHerb í˜ì´ì§€ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”
        return {
            'name': self._get_text(soup, '.product-title'),
            'brand': self._get_text(soup, '.brand-name'),
            'price': self._parse_price(soup),
            'serving_size': '',
            'servings_per_container': 0,
            'ingredients': [],
            'other_ingredients': [],
            'warnings': [],
            'product_url': self.url,
            'image_url': ''
        }

    def _parse_reviews(self) -> List[Dict]:
        """ë¦¬ë·° íŒŒì‹±"""
        reviews = []
        # ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
        # ì‹¤ì œ iHerb êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„
        return reviews

    def _get_text(self, soup, selector: str) -> str:
        """ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        element = soup.select_one(selector)
        return element.text.strip() if element else ''

    def _parse_price(self, soup) -> float:
        """ê°€ê²© íŒŒì‹±"""
        # ì‹¤ì œ êµ¬í˜„
        return 0.0
```

### 3. `data_cleaner.py`

```python
# data_manager/data_cleaner.py
import re
from typing import List, Dict

class ReviewCleaner:
    """ë¦¬ë·° ë°ì´í„° ì •ì œ í´ë˜ìŠ¤"""

    def clean(self, reviews: List[Dict]) -> List[Dict]:
        """ë¦¬ë·° ë°ì´í„° ì •ì œ"""
        cleaned = []
        seen_texts = set()

        for review in reviews:
            # ì¤‘ë³µ ì œê±°
            text = review.get('text', '').strip()
            if not text or text in seen_texts:
                continue
            seen_texts.add(text)

            # í…ìŠ¤íŠ¸ ì •ì œ
            review['text'] = self.clean_text(text)

            # ìœ íš¨ì„± ê²€ì‚¬
            if self.validate_review(review):
                cleaned.append(review)

        return cleaned

    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        return text.strip()

    def validate_review(self, review: Dict) -> bool:
        """ë¦¬ë·° ìœ íš¨ì„± ê²€ì‚¬"""
        return (
            review.get('text') and
            len(review.get('text', '')) >= 10 and  # ìµœì†Œ ê¸¸ì´
            review.get('rating') is not None and
            1 <= review.get('rating', 0) <= 5
        )


class TagNormalizer:
    """íƒœê·¸ ì •ê·œí™” í´ë˜ìŠ¤"""

    # ì¬êµ¬ë§¤ ê´€ë ¨ í‚¤ì›Œë“œ
    REORDER_KEYWORDS = [
        'reorder', 'repurchase', 'buy again', 'order again',
        'ì¬êµ¬ë§¤', 'ë˜ ì‚´', 'ë‹¤ì‹œ êµ¬ë§¤'
    ]

    # ì¥ê¸° ì‚¬ìš© ê´€ë ¨ í‚¤ì›Œë“œ
    LONG_USE_KEYWORDS = [
        'month', 'months', 'year', 'years', 'long time',
        'í•œë‹¬', '1ë‹¬', 'ëª‡ë‹¬', 'ê°œì›”', 'ì˜¤ë˜'
    ]

    def normalize(self, reviews: List[Dict]) -> List[Dict]:
        """íƒœê·¸ ì •ë³´ ì •ê·œí™”"""
        for review in reviews:
            text = review.get('text', '').lower()
            review['reorder'] = self._check_reorder(text, review)
            review['one_month_use'] = self._check_long_use(text, review)
        return reviews

    def _check_reorder(self, text: str, review: Dict) -> bool:
        """ì¬êµ¬ë§¤ íƒœê·¸ í™•ì¸"""
        # ê¸°ì¡´ íƒœê·¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if review.get('reorder') is not None:
            return review['reorder']
        # í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        return any(kw in text for kw in self.REORDER_KEYWORDS)

    def _check_long_use(self, text: str, review: Dict) -> bool:
        """ì¥ê¸° ì‚¬ìš© íƒœê·¸ í™•ì¸"""
        if review.get('one_month_use') is not None:
            return review['one_month_use']
        return any(kw in text for kw in self.LONG_USE_KEYWORDS)
```

### 4. `db_uploader.py`

```python
# data_manager/db_uploader.py
from typing import List, Dict
from .supabase_client import SupabaseClient
from .data_cleaner import ReviewCleaner, TagNormalizer

def upload_product_with_reviews(
    client: SupabaseClient,
    product_data: Dict,
    reviews_data: List[Dict]
) -> Dict:
    """
    ì œí’ˆê³¼ ë¦¬ë·°ë¥¼ í•¨ê»˜ ì—…ë¡œë“œ

    Args:
        client: Supabase í´ë¼ì´ì–¸íŠ¸
        product_data: ì œí’ˆ ì •ë³´
        reviews_data: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸

    Returns:
        Dict: ì—…ë¡œë“œ ê²°ê³¼
    """
    # ë°ì´í„° ì •ì œ
    cleaner = ReviewCleaner()
    normalizer = TagNormalizer()

    cleaned_reviews = cleaner.clean(reviews_data)
    normalized_reviews = normalizer.normalize(cleaned_reviews)

    # ì œí’ˆ ì €ì¥
    saved_product = client.insert_product(product_data)
    product_id = saved_product['id']

    # ë¦¬ë·°ì— product_id ì¶”ê°€
    for review in normalized_reviews:
        review['product_id'] = product_id

    # ë¦¬ë·° ì €ì¥
    saved_reviews = client.insert_reviews(normalized_reviews)

    return {
        'product': saved_product,
        'reviews_count': len(saved_reviews)
    }


def upload_all_data():
    """
    ì „ì²´ ë°ì´í„° ì—…ë¡œë“œ ë©”ì¸ í•¨ìˆ˜

    5ê°œ ì œí’ˆ, ê° 20ê°œ ë¦¬ë·° = ì´ 100ê°œ ë¦¬ë·° ì—…ë¡œë“œ
    """
    client = SupabaseClient()

    # ì˜ˆì‹œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” í¬ë¡¤ë§ ë˜ëŠ” ìˆ˜ë™ ìˆ˜ì§‘í•œ ë°ì´í„° ì‚¬ìš©)
    products_data = [
        {
            'product': {
                'name': 'Lutein 20mg with Zeaxanthin',
                'brand': 'NOW Foods',
                'price': 15.99,
                'serving_size': '1 softgel',
                'servings_per_container': 90,
                'ingredients': [
                    {'name': 'Lutein', 'amount': '20mg', 'daily_value': '*'},
                    {'name': 'Zeaxanthin', 'amount': '1mg', 'daily_value': '*'}
                ],
                'other_ingredients': ['Softgel Capsule', 'Rice Bran Oil'],
                'warnings': ['Keep out of reach of children'],
                'product_url': 'https://www.iherb.com/pr/...',
                'image_url': ''
            },
            'reviews': [
                # 20ê°œ ë¦¬ë·° ë°ì´í„°
            ]
        },
        # ë‚˜ë¨¸ì§€ 4ê°œ ì œí’ˆ...
    ]

    results = []
    for data in products_data:
        result = upload_product_with_reviews(
            client,
            data['product'],
            data['reviews']
        )
        results.append(result)
        print(f"âœ… {result['product']['name']}: {result['reviews_count']}ê°œ ë¦¬ë·° ì—…ë¡œë“œ ì™„ë£Œ")

    print(f"\nğŸ‰ ì „ì²´ ì—…ë¡œë“œ ì™„ë£Œ: {len(results)}ê°œ ì œí’ˆ")
    return results


if __name__ == "__main__":
    upload_all_data()
```

---

## ğŸ”„ ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•

### ë°©ë²• 1: í¬ë¡¤ë§ (ìë™ ìˆ˜ì§‘)

```python
from data_manager.scraper import IHerbScraper
from data_manager.db_uploader import upload_product_with_reviews
from data_manager.supabase_client import SupabaseClient

# iHerb ì œí’ˆ URL ëª©ë¡
PRODUCT_URLS = [
    "https://www.iherb.com/pr/now-foods-lutein-20-mg-90-veggie-softgels/...",
    "https://www.iherb.com/pr/doctors-best-lutein-with-lutemax-20-mg-...",
    # ... ë‚˜ë¨¸ì§€ 3ê°œ
]

client = SupabaseClient()

for url in PRODUCT_URLS:
    scraper = IHerbScraper(url, max_reviews=20)
    data = scraper.scrape()

    result = upload_product_with_reviews(
        client,
        data['product'],
        data['reviews']
    )
    print(f"ì—…ë¡œë“œ ì™„ë£Œ: {result['product']['name']}")
```

### ë°©ë²• 2: ìˆ˜ë™ ìˆ˜ì§‘ (JSON/CSV í™œìš©)

```python
import json

# ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
# data/raw_products.json
"""
[
    {
        "product": {
            "name": "NOW Foods Lutein 20mg",
            "brand": "NOW Foods",
            ...
        },
        "reviews": [
            {
                "text": "Great product for eye health...",
                "rating": 5,
                "date": "2024-01-15",
                "reorder": true,
                ...
            },
            ...
        ]
    },
    ...
]
"""

# JSON íŒŒì¼ ë¡œë“œ í›„ ì—…ë¡œë“œ
with open('data/raw_products.json', 'r', encoding='utf-8') as f:
    products_data = json.load(f)

client = SupabaseClient()
for data in products_data:
    upload_product_with_reviews(client, data['product'], data['reviews'])
```

---

## ğŸ“Š ìˆ˜ì§‘ ëŒ€ìƒ ì œí’ˆ ì˜ˆì‹œ (ë£¨í…Œì¸ 5ì¢…)

| # | ì œí’ˆëª… | ë¸Œëœë“œ | íŠ¹ì§• |
|---|--------|--------|------|
| 1 | Lutein 20mg | NOW Foods | ê°€ì„±ë¹„, ì¸ê¸° ì œí’ˆ |
| 2 | Lutein with Lutemax | Doctor's Best | í”„ë¦¬ë¯¸ì—„ ì„±ë¶„ |
| 3 | Lutein 20mg | Jarrow Formulas | ê³ í•¨ëŸ‰ |
| 4 | Eye Promise | Life Extension | ì¢…í•© ëˆˆê±´ê°• |
| 5 | Lutein & Zeaxanthin | California Gold | ì½¤ë³´ ì œí’ˆ |

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ì›¹ ìŠ¤í¬ë˜í•‘ ìœ¤ë¦¬ (í¬ë¡¤ë§ ì‚¬ìš© ì‹œ)
- **robots.txt í™•ì¸**: iHerbì˜ í¬ë¡¤ë§ ì •ì±… í™•ì¸
- **ìš”ì²­ ì§€ì—°**: ê° ìš”ì²­ ì‚¬ì´ 2-3ì´ˆ ëŒ€ê¸°
- **User-Agent ì„¤ì •**: ì •ìƒì ì¸ ë¸Œë¼ìš°ì €ë¡œ ì¸ì‹ë˜ë„ë¡ ì„¤ì •
- **1íšŒì„± ì‘ì—…**: ë°ì´í„° ìˆ˜ì§‘ì€ ì´ˆê¸° 1íšŒë§Œ ì‹¤í–‰

### 2. Supabase ë³´ì•ˆ
- **í™˜ê²½ ë³€ìˆ˜**: SUPABASE_URL, SUPABASE_KEYëŠ” .env íŒŒì¼ì—ì„œ ê´€ë¦¬
- **anon key ì‚¬ìš©**: service_role keyëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- **RLS ì„¤ì •**: Row Level Security í™œì„±í™” ê¶Œì¥

### 3. ë°ì´í„° í’ˆì§ˆ
- **ìµœì†Œ ë¦¬ë·° ê¸¸ì´**: 10ì ì´ìƒ
- **í‰ì  ë²”ìœ„ ê²€ì¦**: 1-5 ì‚¬ì´
- **ë‚ ì§œ í˜•ì‹ í†µì¼**: YYYY-MM-DD
- **ì¤‘ë³µ ì œê±°**: ë™ì¼ í…ìŠ¤íŠ¸ ë¦¬ë·° ì œê±°

### 4. ì—ëŸ¬ í•¸ë“¤ë§
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§
- ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ê¸°ë¡
- ë¶€ë¶„ ì„±ê³µ ì‹œ ë¡¤ë°± ë˜ëŠ” ê³„ì† ì§„í–‰

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```python
# tests/test_data_manager.py
from data_manager.supabase_client import SupabaseClient
from data_manager.data_cleaner import ReviewCleaner, TagNormalizer

def test_supabase_connection():
    client = SupabaseClient()
    products = client.get_all_products()
    assert isinstance(products, list)

def test_review_cleaning():
    cleaner = ReviewCleaner()
    reviews = [
        {'text': 'Great product!', 'rating': 5},
        {'text': 'Great product!', 'rating': 5},  # ì¤‘ë³µ
        {'text': 'Bad', 'rating': 1},  # ë„ˆë¬´ ì§§ìŒ
        {'text': 'This is a valid review with good length.', 'rating': 4}
    ]
    cleaned = cleaner.clean(reviews)
    assert len(cleaned) == 2  # ì¤‘ë³µ, ì§§ì€ ë¦¬ë·° ì œê±°

def test_tag_normalization():
    normalizer = TagNormalizer()
    reviews = [
        {'text': 'Will definitely reorder this!', 'rating': 5},
        {'text': 'Used for 3 months now.', 'rating': 4}
    ]
    normalized = normalizer.normalize(reviews)
    assert normalized[0]['reorder'] == True
    assert normalized[1]['one_month_use'] == True
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Supabase í”„ë¡œì íŠ¸ ìƒì„±
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)
- [ ] products í…Œì´ë¸” ìƒì„±
- [ ] reviews í…Œì´ë¸” ìƒì„±
- [ ] ë£¨í…Œì¸ ì œí’ˆ 5ì¢… ì„ ì •
- [ ] ì œí’ˆ 1: ë°ì´í„° ìˆ˜ì§‘ (20ê°œ ë¦¬ë·°)
- [ ] ì œí’ˆ 2: ë°ì´í„° ìˆ˜ì§‘ (20ê°œ ë¦¬ë·°)
- [ ] ì œí’ˆ 3: ë°ì´í„° ìˆ˜ì§‘ (20ê°œ ë¦¬ë·°)
- [ ] ì œí’ˆ 4: ë°ì´í„° ìˆ˜ì§‘ (20ê°œ ë¦¬ë·°)
- [ ] ì œí’ˆ 5: ë°ì´í„° ìˆ˜ì§‘ (20ê°œ ë¦¬ë·°)
- [ ] ë°ì´í„° ì •ì œ ì™„ë£Œ
- [ ] Supabase ì—…ë¡œë“œ ì™„ë£Œ
- [ ] ë°ì´í„° ê²€ì¦ (ì´ 100ê°œ ë¦¬ë·° í™•ì¸)
- [ ] íŒ€ì› B, Cì—ê²Œ DB ì ‘ê·¼ ì •ë³´ ê³µìœ 

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Supabase Python ë¬¸ì„œ](https://supabase.com/docs/reference/python/introduction)
- [Supabase í…Œì´ë¸” ìƒì„±](https://supabase.com/docs/guides/database/tables)
- [Selenium ê³µì‹ ë¬¸ì„œ](https://www.selenium.dev/documentation/)
- [BeautifulSoup ë¬¸ì„œ](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# SUPABASE_URL, SUPABASE_KEY ì„¤ì •

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install supabase python-dotenv

# 3. Supabaseì—ì„œ í…Œì´ë¸” ìƒì„± (SQL ì—ë””í„° ì‚¬ìš©)

# 4. ë°ì´í„° ì—…ë¡œë“œ
python -m data_manager.db_uploader
```
