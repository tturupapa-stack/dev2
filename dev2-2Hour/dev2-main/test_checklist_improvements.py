"""
ê°œì„ ëœ checklist.py í…ŒìŠ¤íŠ¸
ê°œì„  ì „í›„ ë¹„êµ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'database'))

from mock_data import NORMAL_REVIEW_TEMPLATES, AD_REVIEW_TEMPLATES
from logic_designer import analyze


def test_improvements():
    """ê°œì„ ëœ ë¡œì§ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("ğŸ” ê°œì„ ëœ checklist.py í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        {
            "title": "ì •ìƒ ë¦¬ë·° 1 (ì¬êµ¬ë§¤ í‘œí˜„)",
            "text": "ì¬êµ¬ë§¤ í–ˆì–´ìš”\në‘ë²ˆì§¸ êµ¬ë§¤ì…ë‹ˆë‹¤. íš¨ê³¼ê°€ ìˆëŠ”ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ ëˆˆ ê±´ê°•ì„ ìœ„í•´ ê³„ì† ë¨¹ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤.",
            "expected": "ì •ìƒ"
        },
        {
            "title": "ì •ìƒ ë¦¬ë·° 2 (ì‚¬ìš© í‘œí˜„)",
            "text": "ëˆˆì˜ í”¼ë¡œê°€ ì¤„ì—ˆì–´ìš”\ní•˜ë£¨ì¢…ì¼ ëª¨ë‹ˆí„° ë³´ëŠ” ì¼ì„ í•˜ëŠ”ë°, ë¨¹ê³ ë‚˜ì„œ ëˆˆì´ ì¢€ ëœ ë¹¡ë¹¡í•œ ëŠë‚Œì´ì—ìš”.",
            "expected": "ì •ìƒ"
        },
        {
            "title": "ì •ìƒ ë¦¬ë·° 3 (êµ¬ë§¤ í‘œí˜„)",
            "text": "ê°€ê²© ëŒ€ë¹„ ê´œì°®ìŠµë‹ˆë‹¤\në£¨í…Œì¸ í•¨ëŸ‰ë„ ì ë‹¹í•˜ê³  ê°€ê²©ë„ í•©ë¦¬ì ì´ì–´ì„œ ì¢‹ìŠµë‹ˆë‹¤. ìº¡ìŠ í¬ê¸°ë„ ì‚¼í‚¤ê¸° í¸í•´ìš”.",
            "expected": "ì •ìƒ"
        },
        {
            "title": "ê´‘ê³  ë¦¬ë·° 1 (ê°íƒ„ì‚¬ ë‚¨ë°œ)",
            "text": "ìµœê³ ì˜ ë£¨í…Œì¸! ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤!!!\nì™€ ì§„ì§œ ëŒ€ë°•ì´ì—ìš”!!! ë¨¹ìë§ˆì ë°”ë¡œ íš¨ê³¼ ëŠê¼ˆì–´ìš”!!",
            "expected": "ê´‘ê³ "
        },
        {
            "title": "ê´‘ê³  ë¦¬ë·° 2 (ë¹„í˜„ì‹¤ì  íš¨ê³¼)",
            "text": "ëˆˆ ê±´ê°•ì˜ í˜ëª…!\në‹¨ 3ì¼ë§Œì— ëˆˆì´ í™• ì¢‹ì•„ì¡ŒìŠµë‹ˆë‹¤! ì•ˆê²½ì„ ë²—ì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆì–´ìš”!",
            "expected": "ê´‘ê³ "
        }
    ]

    results = {
        "total": len(test_cases),
        "correct": 0,
        "incorrect": 0,
        "details": []
    }

    for idx, case in enumerate(test_cases, 1):
        print(f"\n[{idx}/{len(test_cases)}] {case['title']}")
        print(f"  ê¸°ëŒ€ ê²°ê³¼: {case['expected']}")

        try:
            result = analyze(
                review_text=case['text'],
                length_score=70,
                repurchase_score=60,
                monthly_use_score=60,
                photo_score=0,
                consistency_score=70,
                api_key=None
            )

            validation = result['validation']
            is_ad = validation['is_ad']
            actual_result = "ê´‘ê³ " if is_ad else "ì •ìƒ"

            print(f"  ì‹¤ì œ ê²°ê³¼: {actual_result}")
            print(f"  ì‹ ë¢°ë„ ì ìˆ˜: {validation['trust_score']}")
            print(f"  ê°ì  í•­ëª©: {validation['detected_count']}ê°œ")
            if validation['reasons']:
                print(f"  ê°ì  ì‚¬ìœ : {', '.join(validation['reasons'][:3])}")

            # ê²°ê³¼ ë¹„êµ
            is_correct = (case['expected'] == actual_result)
            if is_correct:
                print(f"  âœ… ì •ë‹µ!")
                results['correct'] += 1
            else:
                print(f"  âŒ ì˜¤ë‹µ!")
                results['incorrect'] += 1

            results['details'].append({
                'case': case['title'],
                'expected': case['expected'],
                'actual': actual_result,
                'correct': is_correct,
                'trust_score': validation['trust_score'],
                'penalty_count': validation['detected_count']
            })

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            results['incorrect'] += 1

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 80)
    print(f"  - ì´ í…ŒìŠ¤íŠ¸: {results['total']}ê°œ")
    print(f"  - ì •ë‹µ: {results['correct']}ê°œ")
    print(f"  - ì˜¤ë‹µ: {results['incorrect']}ê°œ")
    print(f"  - ì •í™•ë„: {results['correct'] / results['total'] * 100:.1f}%")

    print("\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
    for detail in results['details']:
        status = "âœ…" if detail['correct'] else "âŒ"
        print(f"  {status} {detail['case']}: {detail['expected']} â†’ {detail['actual']} (ì‹ ë¢°ë„: {detail['trust_score']})")

    return results


def compare_with_mock_data():
    """ëª©ì—… ë°ì´í„°ë¡œ ê°œì„  ì „í›„ ë¹„êµ"""
    print("\n" + "=" * 80)
    print("ğŸ”„ ëª©ì—… ë°ì´í„° í…ŒìŠ¤íŠ¸ (ì •ìƒ ë¦¬ë·° ìƒ˜í”Œ)")
    print("=" * 80)

    # ì •ìƒ ë¦¬ë·° 5ê°œë§Œ í…ŒìŠ¤íŠ¸
    sample_reviews = NORMAL_REVIEW_TEMPLATES[:5]

    stats = {
        "total": len(sample_reviews),
        "detected_as_normal": 0,
        "detected_as_ad": 0,
        "avg_trust_score": 0,
        "avg_penalty_count": 0
    }

    trust_scores = []
    penalty_counts = []

    for idx, template in enumerate(sample_reviews, 1):
        review_text = f"{template['title']}\n{template['body']}"

        result = analyze(
            review_text=review_text,
            length_score=70,
            repurchase_score=60,
            monthly_use_score=60,
            photo_score=0,
            consistency_score=70,
            api_key=None
        )

        validation = result['validation']
        is_ad = validation['is_ad']

        if is_ad:
            stats['detected_as_ad'] += 1
        else:
            stats['detected_as_normal'] += 1

        trust_scores.append(validation['trust_score'])
        penalty_counts.append(validation['detected_count'])

        print(f"\n[{idx}/{len(sample_reviews)}] {template['title'][:30]}...")
        print(f"  íŒë³„: {'âŒ ê´‘ê³ ' if is_ad else 'âœ… ì •ìƒ'}")
        print(f"  ì‹ ë¢°ë„: {validation['trust_score']}")
        print(f"  ê°ì : {validation['detected_count']}ê°œ")

    stats['avg_trust_score'] = sum(trust_scores) / len(trust_scores)
    stats['avg_penalty_count'] = sum(penalty_counts) / len(penalty_counts)

    print("\n" + "=" * 80)
    print("ğŸ“Š ëª©ì—… ë°ì´í„° í…ŒìŠ¤íŠ¸ í†µê³„")
    print("=" * 80)
    print(f"  - ì´ ë¦¬ë·°: {stats['total']}ê°œ")
    print(f"  - ì •ìƒ íŒë³„: {stats['detected_as_normal']}ê°œ ({stats['detected_as_normal'] / stats['total'] * 100:.1f}%)")
    print(f"  - ê´‘ê³  íŒë³„: {stats['detected_as_ad']}ê°œ ({stats['detected_as_ad'] / stats['total'] * 100:.1f}%)")
    print(f"  - í‰ê·  ì‹ ë¢°ë„: {stats['avg_trust_score']:.2f}")
    print(f"  - í‰ê·  ê°ì  í•­ëª©: {stats['avg_penalty_count']:.2f}ê°œ")

    print("\nğŸ’¡ ê°œì„  ëª©í‘œ:")
    print(f"  - ì˜¤íƒë¥ (ì •ìƒâ†’ê´‘ê³ ): {'âœ… ê°œì„ ' if stats['detected_as_ad'] < 2 else 'âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”'}")
    print(f"  - í‰ê·  ì‹ ë¢°ë„: {'âœ… ëª©í‘œ ë‹¬ì„±' if stats['avg_trust_score'] >= 50 else 'âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”'}")

    return stats


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("\n" + "=" * 80)
    print("ğŸš€ checklist.py ê°œì„  ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print("\nê°œì„  ì‚¬í•­:")
    print("  1. ê°œì¸ ê²½í—˜ íŒ¨í„´ í™•ì¥: êµ¬ë§¤, ë¨¹, ì‚¬ìš©, ë³µìš©, ì¬êµ¬ë§¤ ë“±")
    print("  2. ë‹¨ì  íšŒí”¼ ì™„í™”: ë‹¤ë¥¸ ê´‘ê³  íŒ¨í„´ê³¼ í•¨ê»˜ ìˆì„ ë•Œë§Œ ê°ì ")
    print("  3. í‚¤ì›Œë“œ ë°˜ë³µ ì„ê³„ê°’: 5 â†’ 7ë¡œ ì™„í™”")

    # 1. ê°œì„  ì‚¬í•­ í…ŒìŠ¤íŠ¸
    test_results = test_improvements()

    # 2. ëª©ì—… ë°ì´í„° í…ŒìŠ¤íŠ¸
    mock_results = compare_with_mock_data()

    # 3. ìµœì¢… í‰ê°€
    print("\n" + "=" * 80)
    print("âœ… ìµœì¢… í‰ê°€")
    print("=" * 80)

    if test_results['correct'] >= 4:
        print("  âœ… ê°œì„  ë¡œì§ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("  âš ï¸ ì¶”ê°€ ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if mock_results['avg_trust_score'] >= 50:
        print("  âœ… í‰ê·  ì‹ ë¢°ë„ ëª©í‘œ ë‹¬ì„±!")
    else:
        print(f"  âš ï¸ í‰ê·  ì‹ ë¢°ë„ {mock_results['avg_trust_score']:.2f} (ëª©í‘œ: 50 ì´ìƒ)")

    if mock_results['detected_as_ad'] / mock_results['total'] <= 0.2:
        print("  âœ… ì •ìƒ ë¦¬ë·° ì˜¤íƒë¥  ê°œì„  ì„±ê³µ!")
    else:
        print(f"  âš ï¸ ì˜¤íƒë¥  {mock_results['detected_as_ad'] / mock_results['total'] * 100:.1f}% (ëª©í‘œ: 20% ì´í•˜)")


if __name__ == "__main__":
    main()
